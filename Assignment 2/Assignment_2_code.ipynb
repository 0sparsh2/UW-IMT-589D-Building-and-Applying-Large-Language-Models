{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 2\n",
        "## Section 2"
      ],
      "metadata": {
        "id": "O57NBSIt1sw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "with open('anne.txt', 'r') as file:\n",
        "  content = file.read().lower()\n",
        "  words = content.split()\n",
        "\n",
        "words = [word for word in words if word.isalpha() and 'æ' not in word]\n",
        "\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "\n",
        "itos = {i:s for s, i in stoi.items()}\n",
        "\n",
        "N = torch.zeros((27,27), dtype=torch.int32)"
      ],
      "metadata": {
        "id": "2O2vTLnG2KtH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-1: Create the dataset\n",
        "inputs, labels = [], []\n",
        "for w in words:\n",
        "  str = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(str, str[1:]):\n",
        "    index1 = stoi[ch1]\n",
        "    index2 = stoi[ch2]\n",
        "    inputs.append(index1)\n",
        "    labels.append(index2)\n",
        "\n",
        "inputs = torch.tensor(inputs)\n",
        "labels = torch.tensor(labels)\n",
        "num = inputs.nelement()\n",
        "print('Number of examples: ', num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yynqpZSP2Reo",
        "outputId": "88603782-7408-4f0c-fa04-5476f2dcbacb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples:  435187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Negative log likelihood\n",
        "\n",
        "# Intitialize the network\n",
        "g = torch.Generator().manual_seed(1234567890)\n",
        "W1 = torch.randn((27,27), generator=g, requires_grad=True)\n",
        "# Step-2: Gradient descent\n",
        "for k in range(10):\n",
        "\n",
        "  # Forward pass\n",
        "  inputs_encoded = F.one_hot(inputs, num_classes=27).float()\n",
        "  logits = inputs_encoded @ W1\n",
        "  counts = logits.exp() # Counts\n",
        "  probs = counts / counts.sum(1, keepdims=True)\n",
        "  loss = -probs[torch.arange(inputs.nelement()), labels].log().mean()\n",
        "  print(loss.item())\n",
        "\n",
        "  # Backward pass\n",
        "  W1.grad = None # Set the gradients to zero\n",
        "  loss.backward()\n",
        "\n",
        "  # Update\n",
        "  W1.data += -50 * W1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yZ8bg_v2WDZ",
        "outputId": "22c281b6-2067-49de-e232-97bf1ebf586d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6767637729644775\n",
            "3.2435972690582275\n",
            "3.0112698078155518\n",
            "2.8654487133026123\n",
            "2.766885280609131\n",
            "2.695883274078369\n",
            "2.6416678428649902\n",
            "2.5989911556243896\n",
            "2.564650058746338\n",
            "2.536466121673584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Method 1\n",
        "\n",
        "# Intitialize the network\n",
        "g = torch.Generator().manual_seed(1234567890)\n",
        "W1 = torch.randn((27,27), generator=g, requires_grad=True)\n",
        "# Step-2: Gradient descent\n",
        "for k in range(10):\n",
        "  # Forward pass\n",
        "  inputs_encoded = F.one_hot(inputs, num_classes=27).float()\n",
        "  logits = inputs_encoded @ W1\n",
        "  loss = F.cross_entropy(logits, labels)\n",
        "  print(loss.item())\n",
        "\n",
        "  # Backward pass\n",
        "  W1.grad = None # Set the gradients to zero\n",
        "  loss.backward()\n",
        "\n",
        "  # Update\n",
        "  W1.data += -50 * W1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejtmYQhO2aX_",
        "outputId": "235c596e-dbb8-41a7-d089-cc8cad77f458"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6767637729644775\n",
            "3.2435972690582275\n",
            "3.0112698078155518\n",
            "2.865447998046875\n",
            "2.766885280609131\n",
            "2.6958835124969482\n",
            "2.6416678428649902\n",
            "2.5989913940429688\n",
            "2.564650058746338\n",
            "2.536465883255005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Method 2\n",
        "\n",
        "# Intitialize the network\n",
        "g = torch.Generator().manual_seed(1234567890)\n",
        "W1 = torch.randn((27,27), generator=g, requires_grad=True)\n",
        "# Step-2: Gradient descent\n",
        "for k in range(10):\n",
        "  # Forward pass\n",
        "  inputs_encoded = F.one_hot(inputs, num_classes=27).float()\n",
        "  logits = inputs_encoded @ W1\n",
        "  yhat  = torch.softmax(logits, dim=-1)\n",
        "  l2    = -yhat.log()[torch.arange(num), labels]\n",
        "  loss = F.cross_entropy(logits, labels)\n",
        "  print(loss.item())\n",
        "\n",
        "  # Backward pass\n",
        "  W1.grad = None # Set the gradients to zero\n",
        "  loss.backward()\n",
        "\n",
        "  # Update\n",
        "  W1.data += -50 * W1.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2JVZqPa2cz6",
        "outputId": "f57be207-a7e3-40a5-f401-b8690c32b4eb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.6767637729644775\n",
            "3.2435972690582275\n",
            "3.0112698078155518\n",
            "2.865447998046875\n",
            "2.766885280609131\n",
            "2.6958835124969482\n",
            "2.6416678428649902\n",
            "2.5989913940429688\n",
            "2.564650058746338\n",
            "2.536465883255005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Section 3"
      ],
      "metadata": {
        "id": "M5x5Mi3ALn3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On running the below code, with the final results it can be observed that the words generated seem closer to realistic words or extensions of realistic words"
      ],
      "metadata": {
        "id": "wCL5fHZ_jCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Open the file in read mode\n",
        "with open('anne.txt', 'r') as file:\n",
        "    content = file.read().lower()\n",
        "    words = content.split()\n",
        "\n",
        "words = [word for word in words if word.isalpha() and 'æ' not in word]\n",
        "\n",
        "# Create a sorted list of unique characters\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s: i+1 for i, s in enumerate(chars)}  # Use 1-based indexing for characters\n",
        "stoi['.'] = 0  # Use '.' as padding or end-of-sequence token\n",
        "itos = {i: s for s, i in stoi.items()}\n",
        "\n",
        "# Step-1: Create the trigram dataset\n",
        "inputs, labels = [], []\n",
        "for w in words:\n",
        "  word = ['.', '.'] + list(w) + ['.']\n",
        "  for ch1, ch2, ch3 in zip(word, word[1:], word[2:]):\n",
        "    # Add start and end tokens to the word\n",
        "        index1 = stoi[ch1]\n",
        "        index2 = stoi[ch2]\n",
        "        index3 = stoi[ch3]\n",
        "        inputs.append([index1, index2])\n",
        "        labels.append(index3)\n",
        "inputs = torch.tensor(inputs)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "\n",
        "num = len(inputs)\n",
        "print('Number of examples:', num)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVY9-G5KL6o8",
        "outputId": "98fa95b9-1ae0-4016-dedb-0f3109be0c7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of examples: 435187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the network\n",
        "g = torch.Generator().manual_seed(1234567890)\n",
        "W1 = torch.randn((27,27), generator=g,requires_grad=True)\n",
        "W2 = torch.randn((27,27), generator=g,requires_grad=True)\n",
        "\n",
        "# Step-2: Gradient descent\n",
        "for epoch in range(15):\n",
        "    # Forward pass\n",
        "    inputs_encoded = F.one_hot(inputs, num_classes=27).float()\n",
        "    logits = torch.add(inputs_encoded[:,0] @ W1, inputs_encoded[:,1]@W2)\n",
        "    counts = logits.exp() # Counts, equivalent to N\n",
        "    prob = counts / counts.sum(1, keepdims=True) # Probabilities for next character\n",
        "    loss = -prob[torch.arange(num), labels].log().mean()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "    # Backward pass\n",
        "    W1.grad = None # Set the gradients to zero\n",
        "    W2.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Update\n",
        "    W1.data += -45 * W1.grad\n",
        "    W2.data += -45 * W2.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAFdcDh5-hnr",
        "outputId": "75ca28d6-498e-4399-f65c-92ae5f8f2f54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.1365885734558105\n",
            "Epoch 2, Loss: 3.3062171936035156\n",
            "Epoch 3, Loss: 2.949286937713623\n",
            "Epoch 4, Loss: 2.769080400466919\n",
            "Epoch 5, Loss: 2.6688058376312256\n",
            "Epoch 6, Loss: 2.633512258529663\n",
            "Epoch 7, Loss: 2.548745632171631\n",
            "Epoch 8, Loss: 2.5178945064544678\n",
            "Epoch 9, Loss: 2.4838078022003174\n",
            "Epoch 10, Loss: 2.4748165607452393\n",
            "Epoch 11, Loss: 2.4124271869659424\n",
            "Epoch 12, Loss: 2.394338369369507\n",
            "Epoch 13, Loss: 2.3933489322662354\n",
            "Epoch 14, Loss: 2.401322841644287\n",
            "Epoch 15, Loss: 2.3382577896118164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step-3: Generate tokens using the trained trigram model\n",
        "g = torch.Generator().manual_seed(1234567890)\n",
        "\n",
        "torch.manual_seed(1234567890)\n",
        "for _ in range(10):\n",
        "    out = []\n",
        "    index1, index2 = 0, 0  # Start with '..' as the initial characters\n",
        "    while True:\n",
        "        inputs_encoded = F.one_hot(torch.tensor([index1, index2]), num_classes=27).float()\n",
        "        logits = torch.add(inputs_encoded[0,:] @ W1, inputs_encoded[1,:] @ W2)\n",
        "        counts = logits.exp() # Counts, equivalent to N\n",
        "        p = counts / counts.sum(0, keepdims=True) # Probabilities for next character\n",
        "        index = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "        out.append(itos[index])\n",
        "        if index == 0:\n",
        "          break\n",
        "        index1 = index2\n",
        "        index2 = index\n",
        "\n",
        "    print(''.join(out))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOwX89Pa4NMq",
        "outputId": "1e16a5b8-32d6-435a-902b-de6920ea026e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iome.\n",
            "to.\n",
            "te.\n",
            "ill.\n",
            "dnndeat.\n",
            "zpghemrwhan.\n",
            "oo.\n",
            "ati.\n",
            "dollen.\n",
            "moor.\n"
          ]
        }
      ]
    }
  ]
}