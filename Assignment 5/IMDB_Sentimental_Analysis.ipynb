{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y77-PxCrWUOw"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load IMDB dataset\n",
        "dataset = load_dataset('imdb')\n",
        "\n",
        "# Get the train dataset\n",
        "train_dataset = dataset['train']\n",
        "\n",
        "# Tokenize input and convert to tensors\n",
        "train_texts = train_dataset['text']\n",
        "train_labels = train_dataset['label']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into train and test sets\n",
        "train_dataset, test_dataset = train_test_split(df, test_size=0.5)"
      ],
      "metadata": {
        "id": "IAIILIdzWVb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = list(train_dataset['text'])\n",
        "train_labels = list(train_dataset['label'])"
      ],
      "metadata": {
        "id": "Y7Yb5DNzWbEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "\n",
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "KRZ-0nAuWdW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5)"
      ],
      "metadata": {
        "id": "TXcLws6AWgNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume we have the following data\n",
        "#train_texts = [\"I love this movie!\", \"This film is terrible...\"]\n",
        "#train_labels = [1, 0]  # 1 is positive, 0 is negative\n",
        "\n",
        "# Tokenize input\n",
        "print('Tokenizing the input...')\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)"
      ],
      "metadata": {
        "id": "neuPOlgOWgQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to tensors\n",
        "print('Converting to tensors...')\n",
        "train_inputs = torch.tensor(train_encodings['input_ids']).to(device)\n",
        "train_labels = torch.tensor(train_labels).to(device)\n",
        "\n",
        "# Create DataLoader\n",
        "print('Loading the data...')\n",
        "train_data = list(zip(train_inputs, train_labels))\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=16)"
      ],
      "metadata": {
        "id": "mQkp4D99WgSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install GPUtil\n",
        "\n",
        "# from GPUtil import showUtilization as gpu_usage\n",
        "\n",
        "# Check GPU usage\n",
        "gpu_usage()"
      ],
      "metadata": {
        "id": "YD277DN0XFeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "vFF1xjOnWgUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Training loop\n",
        "print('Training...')\n",
        "model.train()\n",
        "for epoch in tqdm(range(3)):  # Number of training epochs\n",
        "    print('Epoch: ', epoch)\n",
        "    gpu_usage()\n",
        "    for step, batch in tqdm(enumerate(train_dataloader)):\n",
        "        b_input_ids, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(b_input_ids, labels=b_labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "fotQtv_kWy7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "model.eval()\n",
        "eval_texts = [\"I really enjoyed this film.\", \"I didn't like the movie.\"]\n",
        "eval_labels = [1, 0]"
      ],
      "metadata": {
        "id": "VKCkgRR2W3w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU usage\n",
        "gpu_usage()"
      ],
      "metadata": {
        "id": "qBpLWN4jW_Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clear cache\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "qev-wTLhW3z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU usage\n",
        "gpu_usage()"
      ],
      "metadata": {
        "id": "D9cs-s-VW32a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input\n",
        "eval_encodings = tokenizer(eval_texts, truncation=True, padding=True)\n",
        "\n",
        "# Convert to tensors\n",
        "eval_inputs = torch.tensor(eval_encodings['input_ids']).to(device)\n",
        "eval_labels = torch.tensor(eval_labels).to(device)\n",
        "\n",
        "# Create DataLoader\n",
        "eval_data = list(zip(eval_inputs, eval_labels))\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=16)\n"
      ],
      "metadata": {
        "id": "hw8CXbsfXSr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in eval_dataloader:\n",
        "    b_input_ids, b_labels = batch\n",
        "    b_input_ids = b_input_ids.to('cuda')\n",
        "    b_labels = b_labels.to('cuda')\n",
        "    print(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(b_input_ids, labels=b_labels)\n",
        "    logits = outputs.logits\n",
        "    eval_loss += loss.item()\n",
        "    nb_eval_steps += 1\n",
        "    preds.append(logits.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "K7Ka6qmXXSu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_loss = eval_loss / nb_eval_steps\n",
        "preds = torch.tensor(preds).numpy()\n",
        "pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "eval_labels = eval_labels.cpu()\n",
        "labels_flat = eval_labels.numpy().flatten()\n",
        "eval_accuracy = accuracy_score(labels_flat, pred_flat)\n",
        "\n",
        "print('Validation loss: ', eval_loss)\n",
        "print('Validation Accuracy: ', eval_accuracy)"
      ],
      "metadata": {
        "id": "8xVty_03XSxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}